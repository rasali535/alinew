# AI Chatbot Backend - Architecture Blueprint & Implementation Plan

## ğŸ“‹ Executive Summary

**Project**: Production-Ready Serverless AI Chatbot Backend  
**Runtime**: Node.js (TypeScript) + Express  
**AI Engine**: Gemini 3 Pro via Vertex AI SDK  
**Database**: PostgreSQL with pgvector (Cloud SQL or Supabase)  
**Deployment**: Docker â†’ Google Cloud Run  
**CI/CD**: GitHub Actions  

---

## ğŸ—ï¸ Architecture Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client Layer                          â”‚
â”‚  (Web App, Mobile App, API Consumers)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTPS
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Google Cloud Run                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Express.js API Server (TypeScript)          â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Controllers â”‚  â”‚  Middleware  â”‚  â”‚   Routes    â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚         â”‚                                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚            Service Layer                     â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ ChatService                               â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ GeminiService (Vertex AI SDK)            â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ MemoryService (pgvector)                 â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ SessionService                            â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â”‚         â”‚                                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚         Data Access Layer (DAL)              â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Database Models                           â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Repository Pattern                        â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                       â”‚
              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL + pgvector  â”‚  â”‚   Vertex AI (Gemini)     â”‚
â”‚  (Cloud SQL/Supabase)   â”‚  â”‚   Google Cloud Platform  â”‚
â”‚                         â”‚  â”‚                          â”‚
â”‚  â€¢ Chat History         â”‚  â”‚  â€¢ Gemini 3 Pro API      â”‚
â”‚  â€¢ User Sessions        â”‚  â”‚  â€¢ Embeddings            â”‚
â”‚  â€¢ Vector Embeddings    â”‚  â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google Secret Manager â”‚
â”‚   â€¢ API Keys            â”‚
â”‚   â€¢ DB Credentials      â”‚
â”‚   â€¢ Service Accounts    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
chatbot-backend/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml                 # CI/CD pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ database.ts               # DB connection config
â”‚   â”‚   â”œâ”€â”€ gemini.ts                 # Vertex AI config
â”‚   â”‚   â””â”€â”€ secrets.ts                # Secret Manager integration
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ chat.controller.ts        # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ health.controller.ts      # Health checks
â”‚   â”‚   â””â”€â”€ session.controller.ts     # Session management
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat.service.ts           # Chat orchestration
â”‚   â”‚   â”œâ”€â”€ gemini.service.ts         # Gemini AI integration
â”‚   â”‚   â”œâ”€â”€ memory.service.ts         # Vector memory (pgvector)
â”‚   â”‚   â””â”€â”€ session.service.ts        # Session management
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ chat.repository.ts        # Chat data access
â”‚   â”‚   â”œâ”€â”€ session.repository.ts     # Session data access
â”‚   â”‚   â””â”€â”€ vector.repository.ts      # Vector operations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ chat.model.ts             # Chat message schema
â”‚   â”‚   â”œâ”€â”€ session.model.ts          # Session schema
â”‚   â”‚   â””â”€â”€ types.ts                  # TypeScript interfaces
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.middleware.ts        # Authentication
â”‚   â”‚   â”œâ”€â”€ error.middleware.ts       # Error handling
â”‚   â”‚   â”œâ”€â”€ validation.middleware.ts  # Request validation
â”‚   â”‚   â””â”€â”€ rate-limit.middleware.ts  # Rate limiting
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.routes.ts            # Chat routes
â”‚   â”‚   â”œâ”€â”€ health.routes.ts          # Health routes
â”‚   â”‚   â””â”€â”€ index.ts                  # Route aggregator
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.ts                 # Winston logger
â”‚   â”‚   â”œâ”€â”€ validators.ts             # Input validators
â”‚   â”‚   â””â”€â”€ errors.ts                 # Custom error classes
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ migrations/               # SQL migrations
â”‚   â”‚   â”‚   â”œâ”€â”€ 001_initial_schema.sql
â”‚   â”‚   â”‚   â””â”€â”€ 002_add_pgvector.sql
â”‚   â”‚   â””â”€â”€ seeds/                    # Seed data (optional)
â”‚   â”œâ”€â”€ app.ts                        # Express app setup
â”‚   â””â”€â”€ server.ts                     # Server entry point
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ .env.example                      # Environment template
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile                        # Production container
â”œâ”€â”€ docker-compose.yml                # Local development
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

## ğŸ”§ Technology Stack Details

### Core Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Runtime** | Node.js 20 LTS | JavaScript runtime |
| **Language** | TypeScript 5.x | Type safety |
| **Framework** | Express.js 4.x | Web server framework |
| **AI Engine** | Gemini 3 Pro (Vertex AI) | Conversational AI |
| **Database** | PostgreSQL 15+ | Relational database |
| **Vector Store** | pgvector | Semantic search & memory |
| **ORM** | Prisma or pg (node-postgres) | Database access |
| **Validation** | Zod | Runtime type validation |
| **Logging** | Winston | Structured logging |
| **Testing** | Jest + Supertest | Unit & integration tests |

### Cloud Infrastructure

| Service | Purpose |
|---------|---------|
| **Google Cloud Run** | Serverless container hosting |
| **Cloud SQL (PostgreSQL)** | Managed database |
| **Vertex AI** | Gemini API access |
| **Secret Manager** | Secrets & credentials |
| **Cloud Build** | Container builds (optional) |
| **Artifact Registry** | Docker image storage |

---

## ğŸ” Security Architecture

### Secret Management Strategy

**Option 1: Google Secret Manager (Recommended for Production)**

```typescript
// src/config/secrets.ts
import { SecretManagerServiceClient } from '@google-cloud/secret-manager';

export class SecretManager {
  private client: SecretManagerServiceClient;
  
  async getSecret(secretName: string): Promise<string> {
    const [version] = await this.client.accessSecretVersion({
      name: `projects/${PROJECT_ID}/secrets/${secretName}/versions/latest`
    });
    return version.payload?.data?.toString() || '';
  }
}
```

**Secrets to Store:**
- `DATABASE_URL` - PostgreSQL connection string
- `GEMINI_API_KEY` - Vertex AI credentials
- `JWT_SECRET` - Session token signing
- `API_KEY` - Client authentication (if needed)

**Option 2: Environment Variables (.env for local dev)**

```bash
# .env.example
NODE_ENV=development
PORT=8080

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/chatbot
DATABASE_POOL_MIN=2
DATABASE_POOL_MAX=10

# Gemini / Vertex AI
GOOGLE_CLOUD_PROJECT=your-project-id
VERTEX_AI_LOCATION=us-central1
GEMINI_MODEL=gemini-3-pro

# Security
JWT_SECRET=your-jwt-secret
API_KEY=your-api-key

# Rate Limiting
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100
```

### Authentication & Authorization

```typescript
// src/middleware/auth.middleware.ts
export const authenticateRequest = async (req, res, next) => {
  // Option 1: API Key
  const apiKey = req.headers['x-api-key'];
  
  // Option 2: JWT Token
  const token = req.headers.authorization?.split(' ')[1];
  
  // Option 3: Session-based
  const sessionId = req.cookies.sessionId;
  
  // Validate and attach user context
};
```

---

## ğŸ—„ï¸ Database Schema Design

### PostgreSQL Schema with pgvector

```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Users/Sessions Table
CREATE TABLE sessions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id VARCHAR(255),
  session_token VARCHAR(255) UNIQUE NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP,
  INDEX idx_session_token (session_token),
  INDEX idx_user_id (user_id)
);

-- Chat Messages Table
CREATE TABLE messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,
  role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
  content TEXT NOT NULL,
  tokens_used INTEGER,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_session_id (session_id),
  INDEX idx_created_at (created_at)
);

-- Vector Embeddings for Semantic Search
CREATE TABLE message_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  message_id UUID NOT NULL REFERENCES messages(id) ON DELETE CASCADE,
  embedding vector(768),  -- Gemini embedding dimension
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_message_id (message_id)
);

-- Create vector similarity search index
CREATE INDEX ON message_embeddings USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

-- Conversation Context (for multi-turn memory)
CREATE TABLE conversation_context (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,
  context_summary TEXT,
  message_count INTEGER DEFAULT 0,
  last_updated TIMESTAMP DEFAULT NOW(),
  UNIQUE(session_id)
);
```

### Prisma Schema (Alternative ORM Approach)

```prisma
// prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["postgresqlExtensions"]
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
  extensions = [vector]
}

model Session {
  id           String   @id @default(uuid())
  userId       String?  @map("user_id")
  sessionToken String   @unique @map("session_token")
  metadata     Json     @default("{}")
  createdAt    DateTime @default(now()) @map("created_at")
  updatedAt    DateTime @updatedAt @map("updated_at")
  expiresAt    DateTime? @map("expires_at")
  
  messages     Message[]
  context      ConversationContext?
  
  @@index([sessionToken])
  @@index([userId])
  @@map("sessions")
}

model Message {
  id         String   @id @default(uuid())
  sessionId  String   @map("session_id")
  role       String
  content    String
  tokensUsed Int?     @map("tokens_used")
  metadata   Json     @default("{}")
  createdAt  DateTime @default(now()) @map("created_at")
  
  session    Session  @relation(fields: [sessionId], references: [id], onDelete: Cascade)
  embedding  MessageEmbedding?
  
  @@index([sessionId])
  @@index([createdAt])
  @@map("messages")
}

model MessageEmbedding {
  id        String   @id @default(uuid())
  messageId String   @unique @map("message_id")
  embedding Unsupported("vector(768)")
  createdAt DateTime @default(now()) @map("created_at")
  
  message   Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)
  
  @@map("message_embeddings")
}

model ConversationContext {
  id             String   @id @default(uuid())
  sessionId      String   @unique @map("session_id")
  contextSummary String?  @map("context_summary")
  messageCount   Int      @default(0) @map("message_count")
  lastUpdated    DateTime @default(now()) @map("last_updated")
  
  session        Session  @relation(fields: [sessionId], references: [id], onDelete: Cascade)
  
  @@map("conversation_context")
}
```

---

## ğŸ¤– Gemini Integration Architecture

### Service Layer Design

```typescript
// src/services/gemini.service.ts
import { VertexAI } from '@google-cloud/vertexai';

export class GeminiService {
  private vertexAI: VertexAI;
  private model: GenerativeModel;
  
  constructor() {
    this.vertexAI = new VertexAI({
      project: process.env.GOOGLE_CLOUD_PROJECT,
      location: process.env.VERTEX_AI_LOCATION
    });
    
    this.model = this.vertexAI.getGenerativeModel({
      model: 'gemini-3-pro',
      generationConfig: {
        maxOutputTokens: 2048,
        temperature: 0.7,
        topP: 0.8,
        topK: 40
      }
    });
  }
  
  async generateResponse(
    messages: ChatMessage[],
    context?: string
  ): Promise<GeminiResponse> {
    // Convert chat history to Gemini format
    // Include vector-retrieved context
    // Stream or batch response
  }
  
  async generateEmbedding(text: string): Promise<number[]> {
    // Generate embeddings for semantic search
  }
}
```

### Memory-Augmented Generation (RAG Pattern)

```typescript
// src/services/memory.service.ts
export class MemoryService {
  async retrieveRelevantContext(
    sessionId: string,
    query: string,
    limit: number = 5
  ): Promise<Message[]> {
    // 1. Generate embedding for current query
    const queryEmbedding = await geminiService.generateEmbedding(query);
    
    // 2. Perform vector similarity search
    const relevantMessages = await vectorRepository.findSimilar(
      queryEmbedding,
      sessionId,
      limit
    );
    
    // 3. Return context for prompt augmentation
    return relevantMessages;
  }
  
  async storeMessageWithEmbedding(message: Message): Promise<void> {
    // Store message and generate embedding asynchronously
  }
}
```

---

## ğŸ³ Docker Configuration

### Production Dockerfile

```dockerfile
# Multi-stage build for optimized image size
FROM node:20-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
COPY tsconfig.json ./

# Install dependencies
RUN npm ci --only=production && npm cache clean --force

# Copy source code
COPY src ./src

# Build TypeScript
RUN npm run build

# Production stage
FROM node:20-alpine

WORKDIR /app

# Install dumb-init for proper signal handling
RUN apk add --no-cache dumb-init

# Create non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

# Copy built application
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/package*.json ./

# Switch to non-root user
USER nodejs

# Expose port (Cloud Run uses PORT env var)
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node -e "require('http').get('http://localhost:8080/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

# Use dumb-init to handle signals properly
ENTRYPOINT ["dumb-init", "--"]

# Start application
CMD ["node", "dist/server.js"]
```

### docker-compose.yml (Local Development)

```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://chatbot:chatbot@postgres:5432/chatbot
      - PORT=8080
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./src:/app/src
    command: npm run dev

  postgres:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_USER: chatbot
      POSTGRES_PASSWORD: chatbot
      POSTGRES_DB: chatbot
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./src/database/migrations:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U chatbot"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```

---

## ğŸš€ CI/CD Pipeline (GitHub Actions)

### .github/workflows/deploy.yml

```yaml
name: Deploy to Cloud Run

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  SERVICE_NAME: chatbot-backend
  REGISTRY: us-central1-docker.pkg.dev

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run linter
        run: npm run lint
      
      - name: Run tests
        run: npm test
      
      - name: Build TypeScript
        run: npm run build

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev
      
      - name: Build Docker image
        run: |
          docker build -t ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:${{ github.sha }} .
          docker tag ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:${{ github.sha }} \
                     ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:latest
      
      - name: Push Docker image
        run: |
          docker push ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:${{ github.sha }}
          docker push ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:latest
      
      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/chatbot/${{ env.SERVICE_NAME }}:${{ github.sha }} \
            --region ${{ env.REGION }} \
            --platform managed \
            --allow-unauthenticated \
            --set-env-vars "NODE_ENV=production" \
            --set-secrets "DATABASE_URL=DATABASE_URL:latest,GEMINI_API_KEY=GEMINI_API_KEY:latest" \
            --min-instances 0 \
            --max-instances 10 \
            --memory 512Mi \
            --cpu 1 \
            --timeout 300 \
            --concurrency 80 \
            --service-account chatbot-backend@${{ env.PROJECT_ID }}.iam.gserviceaccount.com
      
      - name: Run database migrations
        run: |
          # Execute migrations via Cloud Run job or Cloud SQL proxy
          echo "Migrations would run here"
```

---

## ğŸ”Œ MCP Server Integration

### Required MCP Servers for Antigravity

To automate resource provisioning and management, install these MCP servers:

#### 1. **Google Cloud MCP Server**
```bash
# Install Google Cloud MCP
npm install -g @modelcontextprotocol/server-google-cloud
```

**Capabilities:**
- Provision Cloud Run services
- Create Cloud SQL instances
- Configure Secret Manager
- Set up IAM roles and service accounts
- Enable Vertex AI API

**Usage in Antigravity:**
```typescript
// Example MCP commands
- "Create a Cloud Run service named chatbot-backend"
- "Provision Cloud SQL PostgreSQL instance with pgvector"
- "Set up Secret Manager secrets for DATABASE_URL and GEMINI_API_KEY"
- "Enable Vertex AI API in project"
```

#### 2. **PostgreSQL MCP Server**
```bash
# Install PostgreSQL MCP
npm install -g @modelcontextprotocol/server-postgres
```

**Capabilities:**
- Execute database migrations
- Run SQL queries
- Manage database schema
- Create indexes and extensions

**Usage in Antigravity:**
```typescript
- "Run migration 001_initial_schema.sql"
- "Enable pgvector extension"
- "Create vector similarity index"
```

#### 3. **GitHub MCP Server**
```bash
# Install GitHub MCP
npm install -g @modelcontextprotocol/server-github
```

**Capabilities:**
- Create repositories
- Set up GitHub Actions workflows
- Manage secrets
- Configure branch protection

**Usage in Antigravity:**
```typescript
- "Create GitHub repository chatbot-backend"
- "Add GitHub secrets: GCP_PROJECT_ID, WIF_PROVIDER, WIF_SERVICE_ACCOUNT"
- "Set up deploy.yml workflow"
```

#### 4. **Docker MCP Server** (Optional)
```bash
# Install Docker MCP
npm install -g @modelcontextprotocol/server-docker
```

**Capabilities:**
- Build Docker images
- Test containers locally
- Push to registries

---

## ğŸ“Š Implementation Phases

### **Phase 1: Project Setup & Foundation** (Week 1)

**Objectives:**
- Initialize Node.js/TypeScript project
- Set up Express server with middleware
- Configure Docker and docker-compose
- Establish project structure and tooling

**Tasks:**
1. âœ… Initialize npm project with TypeScript
2. âœ… Install core dependencies (Express, TypeScript, Winston, etc.)
3. âœ… Configure tsconfig.json and ESLint
4. âœ… Create modular folder structure
5. âœ… Set up Express app with:
   - Error handling middleware
   - Request validation (Zod)
   - Logging (Winston)
   - CORS configuration
   - Rate limiting
6. âœ… Create Dockerfile and docker-compose.yml
7. âœ… Set up health check endpoint (`/health`)
8. âœ… Configure environment variables (.env.example)
9. âœ… Initialize Git repository
10. âœ… Write initial README.md

**Deliverables:**
- Working Express server running in Docker
- Health check endpoint responding
- Structured logging operational
- Local development environment ready

**Validation:**
```bash
docker-compose up
curl http://localhost:8080/health
# Expected: {"status": "ok", "timestamp": "..."}
```

---

### **Phase 2: Gemini AI Integration** (Week 2)

**Objectives:**
- Integrate Vertex AI SDK
- Implement Gemini 3 Pro chat functionality
- Create service layer for AI operations
- Build chat controller and routes

**Tasks:**
1. âœ… Install Vertex AI SDK (`@google-cloud/vertexai`)
2. âœ… Configure Google Cloud authentication
3. âœ… Create `GeminiService` class:
   - Initialize Vertex AI client
   - Implement `generateResponse()` method
   - Implement `generateEmbedding()` method
   - Handle streaming responses (optional)
4. âœ… Create `ChatService` orchestration layer
5. âœ… Build `ChatController`:
   - POST `/api/chat` - Send message
   - GET `/api/chat/:sessionId` - Get chat history
6. âœ… Implement request/response validation
7. âœ… Add error handling for API failures
8. âœ… Write unit tests for GeminiService
9. âœ… Test integration with Gemini API
10. âœ… Document API endpoints (OpenAPI/Swagger)

**Deliverables:**
- Functional chat endpoint
- Gemini responses working
- API documentation
- Unit tests passing

**Validation:**
```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"sessionId": "test-123", "message": "Hello, how are you?"}'
# Expected: {"response": "...", "sessionId": "test-123"}
```

---

### **Phase 3: Database & Memory Layer** (Week 3)

**Objectives:**
- Set up PostgreSQL with pgvector
- Implement database schema and migrations
- Build repository layer for data access
- Integrate vector-based memory retrieval

**Tasks:**
1. âœ… Set up PostgreSQL with pgvector in docker-compose
2. âœ… Create database migration files:
   - `001_initial_schema.sql` (sessions, messages)
   - `002_add_pgvector.sql` (embeddings, indexes)
3. âœ… Choose ORM strategy (Prisma vs raw pg):
   - If Prisma: Create schema.prisma
   - If pg: Create connection pool
4. âœ… Implement repositories:
   - `SessionRepository` - CRUD for sessions
   - `ChatRepository` - Message storage/retrieval
   - `VectorRepository` - Embedding operations
5. âœ… Create `MemoryService`:
   - Store messages with embeddings
   - Retrieve relevant context via vector search
   - Implement RAG pattern
6. âœ… Integrate memory into `ChatService`
7. âœ… Add session management endpoints:
   - POST `/api/sessions` - Create session
   - GET `/api/sessions/:id` - Get session
   - DELETE `/api/sessions/:id` - Delete session
8. âœ… Write integration tests for database layer
9. âœ… Optimize vector search performance
10. âœ… Add database connection health checks

**Deliverables:**
- Working PostgreSQL database with pgvector
- All migrations applied
- Memory-augmented chat responses
- Session management functional

**Validation:**
```bash
# Test vector search
curl -X POST http://localhost:8080/api/chat \
  -d '{"sessionId": "test", "message": "What did we discuss earlier?"}'
# Expected: Response includes context from previous messages
```

---

### **Phase 4: Cloud Run Deployment & Production** (Week 4)

**Objectives:**
- Deploy to Google Cloud Run
- Configure Cloud SQL and Secret Manager
- Set up CI/CD pipeline
- Implement monitoring and observability

**Tasks:**
1. âœ… Create Google Cloud project
2. âœ… Enable required APIs:
   - Cloud Run API
   - Cloud SQL Admin API
   - Vertex AI API
   - Secret Manager API
   - Artifact Registry API
3. âœ… Provision Cloud SQL PostgreSQL instance:
   - Enable pgvector extension
   - Configure private IP (VPC connector)
   - Set up automated backups
4. âœ… Run database migrations on Cloud SQL
5. âœ… Create secrets in Secret Manager:
   - DATABASE_URL
   - GEMINI_API_KEY
   - JWT_SECRET
6. âœ… Create service account with permissions:
   - Cloud SQL Client
   - Secret Manager Secret Accessor
   - Vertex AI User
7. âœ… Build and push Docker image to Artifact Registry
8. âœ… Deploy to Cloud Run:
   - Configure environment variables
   - Attach secrets
   - Set up Cloud SQL connection
   - Configure autoscaling (min: 0, max: 10)
9. âœ… Set up GitHub Actions workflow:
   - Workload Identity Federation
   - Automated testing
   - Docker build and push
   - Cloud Run deployment
10. âœ… Configure monitoring:
    - Cloud Logging integration
    - Error reporting
    - Uptime checks
    - Custom metrics (token usage, response time)
11. âœ… Set up custom domain (optional)
12. âœ… Load testing and performance optimization
13. âœ… Security audit:
    - HTTPS enforcement
    - CORS configuration
    - Rate limiting
    - Input validation
14. âœ… Documentation:
    - Deployment guide
    - API documentation
    - Troubleshooting guide

**Deliverables:**
- Production chatbot running on Cloud Run
- Automated CI/CD pipeline
- Monitoring and logging configured
- Complete documentation

**Validation:**
```bash
# Test production endpoint
curl -X POST https://chatbot-backend-xxxxx.run.app/api/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-api-key" \
  -d '{"sessionId": "prod-test", "message": "Hello production!"}'

# Check health
curl https://chatbot-backend-xxxxx.run.app/health
```

---

## ğŸ“ˆ Performance & Scalability Considerations

### Cloud Run Configuration

```yaml
Resources:
  CPU: 1 vCPU
  Memory: 512 Mi (adjust based on load)
  
Autoscaling:
  Min Instances: 0 (cost optimization)
  Max Instances: 10 (adjust based on traffic)
  Concurrency: 80 requests per instance
  
Timeout: 300 seconds (for long-running AI requests)
```

### Database Connection Pooling

```typescript
// src/config/database.ts
export const poolConfig = {
  min: 2,
  max: 10,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
};
```

### Caching Strategy

```typescript
// Optional: Redis for session caching
- Cache frequently accessed sessions
- Store rate limit counters
- Cache Gemini responses for identical queries
```

### Cost Optimization

1. **Cloud Run**: Pay-per-use, scale to zero
2. **Cloud SQL**: Use shared-core instance for dev/staging
3. **Vertex AI**: Monitor token usage, implement request batching
4. **Secrets**: Minimal cost, cache in memory after retrieval

---

## ğŸ§ª Testing Strategy

### Test Pyramid

```
        /\
       /E2E\         - Full API flow tests
      /------\
     /  INT   \      - Service integration tests
    /----------\
   /    UNIT    \    - Pure function tests
  /--------------\
```

### Test Files

```typescript
// tests/unit/services/gemini.service.test.ts
describe('GeminiService', () => {
  it('should generate response from Gemini API', async () => {
    // Mock Vertex AI client
    // Test response generation
  });
});

// tests/integration/chat.integration.test.ts
describe('Chat API', () => {
  it('should create session and send message', async () => {
    // Test full flow with test database
  });
});

// tests/e2e/chat-flow.e2e.test.ts
describe('Chat E2E Flow', () => {
  it('should maintain conversation context', async () => {
    // Test multi-turn conversation
  });
});
```

---

## ğŸ“ API Endpoints Summary

### Chat Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat` | Send message and get AI response |
| GET | `/api/chat/:sessionId` | Get chat history for session |
| DELETE | `/api/chat/:sessionId` | Clear chat history |

### Session Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/sessions` | Create new session |
| GET | `/api/sessions/:id` | Get session details |
| DELETE | `/api/sessions/:id` | Delete session |

### Utility Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/metrics` | Prometheus metrics (optional) |

---

## ğŸ” Monitoring & Observability

### Logging Structure

```typescript
// Winston logger configuration
logger.info('Chat request received', {
  sessionId: 'xxx',
  messageLength: 50,
  timestamp: new Date().toISOString()
});

logger.error('Gemini API error', {
  error: error.message,
  stack: error.stack,
  sessionId: 'xxx'
});
```

### Key Metrics to Track

1. **Request Metrics**:
   - Request count
   - Response time (p50, p95, p99)
   - Error rate

2. **AI Metrics**:
   - Gemini API latency
   - Token usage per request
   - Embedding generation time

3. **Database Metrics**:
   - Query execution time
   - Connection pool utilization
   - Vector search performance

4. **Business Metrics**:
   - Active sessions
   - Messages per session
   - User retention

---

## ğŸš¨ Error Handling Strategy

### Error Types

```typescript
// src/utils/errors.ts
export class AppError extends Error {
  constructor(
    public statusCode: number,
    public message: string,
    public isOperational: boolean = true
  ) {
    super(message);
  }
}

export class ValidationError extends AppError {
  constructor(message: string) {
    super(400, message);
  }
}

export class GeminiAPIError extends AppError {
  constructor(message: string) {
    super(502, `Gemini API Error: ${message}`);
  }
}

export class DatabaseError extends AppError {
  constructor(message: string) {
    super(500, `Database Error: ${message}`);
  }
}
```

### Global Error Handler

```typescript
// src/middleware/error.middleware.ts
export const errorHandler = (err, req, res, next) => {
  logger.error('Error occurred', {
    error: err.message,
    stack: err.stack,
    path: req.path
  });
  
  if (err instanceof AppError && err.isOperational) {
    return res.status(err.statusCode).json({
      status: 'error',
      message: err.message
    });
  }
  
  // Unknown errors
  res.status(500).json({
    status: 'error',
    message: 'Internal server error'
  });
};
```

---

## ğŸ“š Additional Resources

### Documentation to Create

1. **README.md** - Project overview and quick start
2. **DEPLOYMENT.md** - Detailed deployment instructions
3. **API.md** - Complete API documentation
4. **CONTRIBUTING.md** - Development guidelines
5. **ARCHITECTURE.md** - This document (expanded)

### Recommended Tools

- **Postman/Insomnia**: API testing
- **pgAdmin**: Database management
- **Cloud Console**: GCP resource management
- **Grafana**: Advanced monitoring (optional)

---

## âœ… Pre-Deployment Checklist

- [ ] All tests passing (unit, integration, e2e)
- [ ] Environment variables configured in Secret Manager
- [ ] Database migrations applied to Cloud SQL
- [ ] Service account permissions verified
- [ ] API endpoints documented
- [ ] Error handling tested
- [ ] Rate limiting configured
- [ ] CORS settings verified
- [ ] Logging and monitoring active
- [ ] Security audit completed
- [ ] Load testing performed
- [ ] Backup strategy implemented
- [ ] Rollback plan documented

---

## ğŸ¯ Success Criteria

### Technical Success
- âœ… API response time < 2 seconds (p95)
- âœ… 99.9% uptime
- âœ… Zero data loss
- âœ… Successful autoscaling under load
- âœ… All security best practices implemented

### Business Success
- âœ… Coherent multi-turn conversations
- âœ… Relevant context retrieval from memory
- âœ… Cost-efficient operation (< $X per 1000 requests)
- âœ… Easy to maintain and extend

---

## ğŸ“ Next Steps

**Awaiting your feedback on:**

1. **Database Choice**: Cloud SQL vs Supabase preference?
2. **ORM Strategy**: Prisma vs raw node-postgres?
3. **Authentication**: API key, JWT, or session-based?
4. **Streaming**: Should Gemini responses stream or batch?
5. **Additional Features**: 
   - Multi-language support?
   - File upload handling?
   - Voice input/output?
6. **Budget Constraints**: Any cost limitations to consider?

**Ready to proceed with Phase 1 upon your approval!**

---

*This blueprint provides a comprehensive foundation for building a production-ready AI chatbot backend. Each phase is designed to be iterative and testable, ensuring a robust and scalable solution.*
